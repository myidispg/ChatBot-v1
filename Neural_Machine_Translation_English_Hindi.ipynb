{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Machine Translation English-Hindi.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myidispg/NLP-Projects/blob/master/Neural_Machine_Translation_English_Hindi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8MDJXskZOXRe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# My first Google Colab notebook for Neural Machine Translation in Pytorch.\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "WDPUkqq_oNlz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **The necessary imports and running the code on GPU if available.**\n",
        "GPU is necessary for faster model training."
      ]
    },
    {
      "metadata": {
        "id": "-ihN_CB6Nvcd",
        "colab_type": "code",
        "outputId": "1b319bfa-4b9c-4267-895a-b67d4430096e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "import random\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "device"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "JBvdiuH4rSjm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Download and save the dataset"
      ]
    },
    {
      "metadata": {
        "id": "iYvYgfnGojvi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_url = 'http://www.cfilt.iitb.ac.in/iitb_parallel/iitb_corpus_download/parallel.tgz'\n",
        "# tgz_file = requests.get(dataset_url, stream=True)\n",
        "\n",
        "# if path.exists(\"parallel.tgz\"):\n",
        "#   os.remove('parallel.tgz')\n",
        "#   print('Removed the existing copy')\n",
        "\n",
        "# with open(\"parallel.tgz\", \"wb\") as f:\n",
        "#   for chunk in tgz_file.iter_content(chunk_size=1024):\n",
        "#     if chunk:\n",
        "#       f.write(chunk)\n",
        "      \n",
        "# if path.exists(\"parallel.tgz\"):\n",
        "#   print('File saved successfully.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aqNB2hsCdRgW",
        "colab_type": "code",
        "outputId": "d48ed5ab-f9da-4199-f896-470eb511bae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "if path.exists('parallel.tgz'):\n",
        "  print('Deleting existing copy.')\n",
        "  os.remove('parallel.tgz')\n",
        "  print('Downloading dataset...')\n",
        "  from urllib.request import urlretrieve\n",
        "  urlretrieve(dataset_url, 'parallel.tgz')\n",
        "  print('Dataset downloaded successfully!')\n",
        "else:\n",
        "  print('Downloading dataset...')\n",
        "  from urllib.request import urlretrieve\n",
        "  urlretrieve(dataset_url, 'parallel.tgz')\n",
        "  print('Dataset downloaded successfully!')  \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleting existing copy.\n",
            "Downloading dataset...\n",
            "Dataset downloaded successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3RpEwje4rW5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73c7859d-59c3-4338-929e-686eb06c56ee"
      },
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "\n",
        "tar = tarfile.open(\"parallel.tgz\")\n",
        "tarinfo = tarfile.TarInfo(tar)\n",
        "for member in tar.getmembers():\n",
        "#   print(member)\n",
        "  f = tar.extractfile(member)\n",
        "#   print(f)\n",
        "  if f is not None:\n",
        "    data_list.append(f)\n",
        "\n",
        "data_list\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<ExFileObject name='parallel.tgz'>, <ExFileObject name='parallel.tgz'>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "THtBuDiYsoTm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define a class for a Language\n",
        "This class will contain the word2idx, idx2word, number of words in the vocabulary and max sentence length of that language."
      ]
    },
    {
      "metadata": {
        "id": "DN92m4znsnVC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "        self.max_sent_length = 1\n",
        "        \n",
        "    def addSentence(self, sentence):\n",
        "        sent_length = len(sentence.split(' '))\n",
        "        self.max_sent_length = sent_length if sent_length > self.max_sent_length else self.max_sent_length        \n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "    \n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "            \n",
        "            \n",
        "hindi_lang = Lang('hindi')\n",
        "english_lang = Lang('english')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nX9TPlKJSU2G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Use the .tgz file and read the ExFileObject to get the list of lines and read in utf-8 format"
      ]
    },
    {
      "metadata": {
        "id": "1ilexu_CN-7N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a11e9c5c-64cd-4881-b6ae-2d0a2b18dfc5"
      },
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "bytecode_lines = data_list[1].readlines()\n",
        "\n",
        "english_lines = []\n",
        "\n",
        "for line in bytecode_lines:\n",
        "  english_lines.append(normalizeString(line.decode('utf-8').strip('\\n')))\n",
        "  \n",
        "hindi_lines = []\n",
        "bytecode_lines = data_list[0].readlines()\n",
        "\n",
        "for line in bytecode_lines:\n",
        "  hindi_lines.append(line.decode('utf-8').strip('\\n'))\n",
        "  \n",
        "print(f' The first 10 english lines are- {english_lines[:10]}')\n",
        "print(f' The first 10 hindi lines are- {hindi_lines[:10]}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " The first 10 english lines are- ['give your application an accessibility workout', 'accerciser accessibility explorer', 'the default plugin layout for the bottom panel', 'the default plugin layout for the top panel', 'a list of plugins that are disabled by default', 'highlight duration', 'the duration of the highlight box when selecting accessible nodes', 'highlight border color', 'the color and opacity of the highlight border .', 'highlight fill color']\n",
            " The first 10 hindi lines are- ['अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें', 'एक्सेर्साइसर पहुंचनीयता अन्वेषक', 'निचले पटल के लिए डिफोल्ट प्लग-इन खाका', 'ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका', 'उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है', 'अवधि को हाइलाइट रकें', 'पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्से की अवधि', 'सीमांत (बोर्डर) के रंग को हाइलाइट करें', 'हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता। ', 'भराई के रंग को हाइलाइट करें']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xmm5MrNftCyW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Some helper functions to read the data, create pairs and the language vocabularies."
      ]
    },
    {
      "metadata": {
        "id": "uankOoTls5bq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "82b3629d-0f1e-4471-e401-28f5ae26be84"
      },
      "cell_type": "code",
      "source": [
        "def addWordsToLang(lang, lines):\n",
        "    for line in lines:\n",
        "        lang.addSentence(line)\n",
        "    \n",
        "    return lang\n",
        "\n",
        "def create_pairs(lang1, lang2):\n",
        "    pairs = []\n",
        "\n",
        "    for lang1_sent, lang2_sent in zip(lang1, lang2):\n",
        "        pairs.append([lang1_sent, lang2_sent])\n",
        "        \n",
        "    return pairs\n",
        "\n",
        "def createLanguagesAndPairs(lang1_lines, lang2_lines, lang1, lang2):\n",
        "    \n",
        "    print('Creating pairs...')\n",
        "    pairs = create_pairs(lang1_lines, lang2_lines)\n",
        "    \n",
        "    print('Adding words to languages')\n",
        "    lang1 = addWordsToLang(lang1, lang1_lines)\n",
        "    lang2 = addWordsToLang(lang2, lang2_lines)\n",
        "    \n",
        "    print('Done creating languages')\n",
        "    \n",
        "    return pairs, lang1, lang2\n",
        "  \n",
        "pairs, english_lang, hindi_lang = createLanguagesAndPairs(english_lines, hindi_lines, english_lang, hindi_lang)\n",
        "\n",
        "print(f'The first 10 pairs are- {pairs[:10]}\\n')\n",
        "\n",
        "MAX_LENGTH = english_lang.max_sent_length if english_lang.max_sent_length > hindi_lang.max_sent_length else hindi_lang.max_sent_length\n",
        "print(f'No of words in english: {english_lang.n_words}, No of words in hindi: {hindi_lang.n_words}, Max length of sentence in both: {MAX_LENGTH}')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating pairs...\n",
            "Adding words to languages\n",
            "Done creating languages\n",
            "The first 10 pairs are- [['give your application an accessibility workout', 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'], ['accerciser accessibility explorer', 'एक्सेर्साइसर पहुंचनीयता अन्वेषक'], ['the default plugin layout for the bottom panel', 'निचले पटल के लिए डिफोल्ट प्लग-इन खाका'], ['the default plugin layout for the top panel', 'ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका'], ['a list of plugins that are disabled by default', 'उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है'], ['highlight duration', 'अवधि को हाइलाइट रकें'], ['the duration of the highlight box when selecting accessible nodes', 'पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्से की अवधि'], ['highlight border color', 'सीमांत (बोर्डर) के रंग को हाइलाइट करें'], ['the color and opacity of the highlight border .', 'हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता। '], ['highlight fill color', 'भराई के रंग को हाइलाइट करें']]\n",
            "\n",
            "No of words in english: 182705, No of words in hindi: 536013, Max length of sentence in both: 1469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r1CyMlN3Sqvl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Encoder RNN\n",
        "Create an Encoder RNN. \n",
        "It takes the input size which is the number of words in the input language vocabulary.\n",
        "The other argument is the hidden state dimension. The dimensions of the embedidng is also the same as the hidden state dimensions.\n",
        "\n",
        "\n",
        "\n",
        "![The Encoder RNN Image](https://pytorch.org/tutorials/_images/encoder-network.png)"
      ]
    },
    {
      "metadata": {
        "id": "4R5273ecSqc0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "       \n",
        "    self.embedding = nn.Embedding(input_size, hidden_size) # Dimensions-> hidden_size\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size) # input dimension is hidden_size due to embedding ^\n",
        "        \n",
        "  def forward(self, input, hidden):\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\n",
        "    output = embedded\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "#     print(f'Encoder Output shape: {output.shape}')\n",
        "    return output, hidden\n",
        "    \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7N2skMGdUOL-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Create Decoder RNN\n",
        "Create the DecoderRNN. It takes the hidden unit dimensions and the number of words in the output language vocabulary.\n",
        "\n",
        "\n",
        "![DecoderRNN architecture](https://pytorch.org/tutorials/_images/decoder-network.png)"
      ]
    },
    {
      "metadata": {
        "id": "R-ya0R_BUn4p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "   \n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size) # This turns the output to be of dimension -> embedding dimension x no of words in output vocab.\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "  def forward(self, input, hidden_state):\n",
        "    output = self.embedding(input).view(1, 1, -1)\n",
        "    output = F.relu(output)\n",
        "    output, hidden_state = self.gru(output, hidden_state)\n",
        "#     print(f'Decoder output shape: {self.out(output[0]).shape}')\n",
        "    output = self.softmax(self.out(output[0]))\n",
        "#     print(f'Decoder embedding shape: {output.shape}')\n",
        "    return output, hidden_state\n",
        "    \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ly5NOpzMUuud",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Training section.\n",
        "Some functions to create a sequence of inputs for each sentence pair.\n"
      ]
    },
    {
      "metadata": {
        "id": "eOX6A3jvU3I0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "    \n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorFromPairs(pair):\n",
        "    input_tensor = tensorFromSentence(english_lang, pair[0])\n",
        "    output_tensor = tensorFromSentence(hindi_lang, pair[1])\n",
        "    return (input_tensor, output_tensor)\n",
        "\n",
        "# # This section is for testing the outputs of the Encoder\n",
        "# input_tensor, output_tensor = tensorFromPairs(pairs[0])\n",
        "\n",
        "# HIDDEN_DIM = 256\n",
        "# encoder = EncoderRNN(english_lang.n_words, HIDDEN_DIM).to(device)\n",
        "# decoder = DecoderRNN(HIDDEN_DIM, hindi_lang.n_words).to(device)\n",
        "\n",
        "# encoder_hidden = encoder.initHidden()\n",
        "\n",
        "# encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n",
        "# decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n",
        "\n",
        "# encoder_optimizer.zero_grad()\n",
        "# decoder_optimizer.zero_grad()\n",
        "\n",
        "# encoder_output, encoder_hidden = encoder(input_tensor[0], encoder_hidden)\n",
        "\n",
        "# print(f'encoder_output- \\n{encoder_output}\\nencoder_hidden- {encoder_hidden}\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cMRFqPWwJbgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3e5f797b-dc16-4bfe-af75-db831bf17486"
      },
      "cell_type": "code",
      "source": [
        "input_tensor, output_tensor = tensorFromPairs(pairs[1000])\n",
        "print(f'Input tensor- {input_tensor}\\nOutput tensor- {output_tensor}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input tensor- tensor([[26],\n",
            "        [27],\n",
            "        [ 1]], device='cuda:0')\n",
            "Output tensor- tensor([[31],\n",
            "        [ 4],\n",
            "        [32],\n",
            "        [33],\n",
            "        [ 1]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jhi4kGkUEfyW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Teacher forcing** is the concept of using the real target outputs as each next input,  instead of using the decoder’s guess as the next input. Using teacher forcing  causes it to converge faster but when the trained network is exploited, it may exhibit instability."
      ]
    },
    {
      "metadata": {
        "id": "UjO2-7s-Em46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length):\n",
        "  encoder_hidden = encoder.initHidden()\n",
        "  \n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  \n",
        "  input_length = input_tensor.size(0)\n",
        "  output_length = target_tensor.size(0)\n",
        "#   print(f'target tensor: {target_tensor} and output length: {output_length}')\n",
        "  \n",
        "  encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "  \n",
        "  loss = 0\n",
        "  \n",
        "  for ei in range(input_length):\n",
        "    encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "    encoder_outputs[ei] = encoder_output[0, 0]\n",
        "    \n",
        "  decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "  \n",
        "  decoder_hidden = encoder_hidden\n",
        "  \n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "  \n",
        "  if use_teacher_forcing:\n",
        "    for di in range(output_length):\n",
        "      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "#       print(f'decoder output: {decoder_output.shape}, output_tensor[{di}]: {output_tensor[di]}')\n",
        "#       print(f'loss: {criterion(decoder_output, output_tensor[di])}')\n",
        "#       print(f'{di}')\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      decoder_input = target_tensor[di]\n",
        "      \n",
        "  else:\n",
        "    for di in range(output_length):\n",
        "      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_token:\n",
        "        break\n",
        "        \n",
        "  loss.backward()\n",
        "  \n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "  \n",
        "  return loss.item() / output_length  \n",
        "\n",
        "\n",
        "def train(input_tensor, output_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    \n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    \n",
        "    input_length = input_tensor.shape[0]\n",
        "    output_length = output_tensor.shape[0]\n",
        "    \n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "    \n",
        "    loss = 0\n",
        "    \n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "    \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    \n",
        "    decoder_hidden = encoder_hidden\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "    \n",
        "    if use_teacher_forcing:\n",
        "        for di in range(output_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            \n",
        "            loss += criterion(decoder_output, output_tensor[di])\n",
        "            decoder_input = output_tensor[di]  # Teacher forcing\n",
        "    else:\n",
        "        for di in range(output_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach() # detach from history as input\n",
        "            loss += criterion(decoder_output, output_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    \n",
        "    return loss.item() / output_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3tfHsDWUPCix",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Some functions to find time elapsed\n",
        "These functions help to calculate the elapsed time and the remaining time.\n"
      ]
    },
    {
      "metadata": {
        "id": "f-fidD-XPLI0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_l_hA-Zh92BL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Function to plot the losses\n"
      ]
    },
    {
      "metadata": {
        "id": "XlUZvQ8k95SP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bFiwZGqXPPfL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### This function goes through all the pairs and calls the train() function."
      ]
    },
    {
      "metadata": {
        "id": "CulLehO5PZKo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=10000, learning_rate=0.01):\n",
        "  start = time.time()\n",
        "  plot_losses = []\n",
        "  print_loss_total = 0\n",
        "  plot_loss_total = 0\n",
        "  \n",
        "  training_pairs = [tensorFromPairs(random.choice(pairs)) for i in range(n_iters)]\n",
        "  print(f'The number of training_pairs is {len(training_pairs)}\\n\\n\\n')\n",
        "  \n",
        "  encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "  \n",
        "  for iter in range(1, n_iters+1):\n",
        "    training_pair = training_pairs[iter-1]\n",
        "    input_tensor = training_pair[0]\n",
        "    target_tensor = training_pair[1]\n",
        "    \n",
        "    loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length = MAX_LENGTH)\n",
        "    \n",
        "    print_loss_total += loss\n",
        "    plot_loss_total += loss\n",
        "    \n",
        "    if iter % print_every == 0:\n",
        "      print_loss_avg = print_loss_total / print_every\n",
        "      print_loss_total = 0\n",
        "      print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "    if iter % plot_every == 0:\n",
        "      plot_loss_avg = plot_loss_total / plot_every\n",
        "      plot_losses.append(plot_loss_avg)\n",
        "      plot_loss_total = 0\n",
        "  \n",
        "  showPlot(plot_losses) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mqrlhPO00jLK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Evaluation\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "E9wgHtcK0viY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length = MAX_LENGTH):\n",
        "  with torch.no_grad():\n",
        "    input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "    input_length = input_tensor.shape[0]\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    \n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "    \n",
        "    for ei in range(input_length):\n",
        "      encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "      encoder_outputs[ei] += encoder_output[0, 0]\n",
        "      \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    decoded_words = []\n",
        "    decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "    for di in range(max_length):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      decoder_attentions[di] = decoder_attention.data\n",
        "      topv, topi = decoder_output.data.topk(1)\n",
        "      if topi.item() == EOS_token:\n",
        "          decoded_words.append('<EOS>')\n",
        "          break\n",
        "      else:\n",
        "          decoded_words.append(output_lang.index2word[topi.item()])\n",
        "      decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    return decoded_words, decoder_attentions[:di + 1]\n",
        "      \n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h4FXeGNl23Si",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Training the Seq2Seq Model now."
      ]
    },
    {
      "metadata": {
        "id": "THQ31E-w27GY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6384cbe0-5acb-4ebe-cfdc-8e90635f62da"
      },
      "cell_type": "code",
      "source": [
        "HIDDEN_DIM = 32\n",
        "\n",
        "print(f'Executing training on: {device}')\n",
        "encoder = EncoderRNN(english_lang.n_words, HIDDEN_DIM).to(device)\n",
        "decoder = DecoderRNN(HIDDEN_DIM, hindi_lang.n_words).to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "print('Training model now...')\n",
        "trainIters(encoder, decoder, 75000, print_every=250, learning_rate=0.005)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing training on: cuda\n",
            "Training model now...\n",
            "The number of training_pairs is 75000\n",
            "\n",
            "\n",
            "\n",
            "0m 46s (- 230m 29s) (250 0%) 8.5635\n",
            "1m 14s (- 185m 22s) (500 0%) 6.4313\n",
            "1m 49s (- 180m 23s) (750 1%) 6.3634\n",
            "2m 26s (- 180m 53s) (1000 1%) 6.2075\n",
            "3m 3s (- 180m 19s) (1250 1%) 6.2043\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}