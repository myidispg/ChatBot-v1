{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Machine Translation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myidispg/NLP-Projects/blob/master/Neural_Machine_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8MDJXskZOXRe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# My first Google Colab notebook for Neural Machine Translation in Pytorch.\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "WDPUkqq_oNlz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **The necessary imports and running the code on GPU if available.**\n",
        "GPU is necessary for faster model training."
      ]
    },
    {
      "metadata": {
        "id": "-ihN_CB6Nvcd",
        "colab_type": "code",
        "outputId": "215c665b-780b-4d2b-a9ee-bd337aea31c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import requests\n",
        "import tarfile\n",
        "from os import path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "device"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "JBvdiuH4rSjm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Download and save the dataset"
      ]
    },
    {
      "metadata": {
        "id": "iYvYgfnGojvi",
        "colab_type": "code",
        "outputId": "a48364e8-4f80-4c49-c4f2-debf85e676a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dataset_url = 'http://www.cfilt.iitb.ac.in/iitb_parallel/iitb_corpus_download/parallel.tgz'\n",
        "tgz_file = requests.get(dataset_url, stream=True)\n",
        "\n",
        "with open(\"parallel.tgz\", \"wb\") as f:\n",
        "  for chunk in tgz_file.iter_content(chunk_size=1024):\n",
        "    if chunk:\n",
        "      f.write(chunk)\n",
        "      \n",
        "if path.exists(\"parallel.tgz\"):\n",
        "  print('File saved successfully.')\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File saved successfully.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3RpEwje4rW5v",
        "colab_type": "code",
        "outputId": "c8de365c-3fc8-48ec-e035-1df6b5d9bb03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "\n",
        "tar = tarfile.open(\"parallel.tgz\")\n",
        "for member in tar.getmembers():\n",
        "  f = tar.extractfile(member)\n",
        "  if f is not None:\n",
        "    data_list.append(f)\n",
        "\n",
        "data_list\n",
        "  "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<ExFileObject name='parallel.tgz'>, <ExFileObject name='parallel.tgz'>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "THtBuDiYsoTm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define a class for a Language\n",
        "This class will contain the word2idx, idx2word, number of words in the vocabulary and max sentence length of that language."
      ]
    },
    {
      "metadata": {
        "id": "DN92m4znsnVC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "        self.max_sent_length = 1\n",
        "        \n",
        "    def addSentence(self, sentence):\n",
        "        sent_length = len(sentence.split(' '))\n",
        "        self.max_sent_length = sent_length if sent_length > self.max_sent_length else self.max_sent_length        \n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "    \n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "            \n",
        "            \n",
        "hindi_lang = Lang('hindi')\n",
        "english_lang = Lang('english')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nX9TPlKJSU2G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Use the .tgz file and read the ExFileObject to get the list of lines and read in utf-8 format"
      ]
    },
    {
      "metadata": {
        "id": "1ilexu_CN-7N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bytecode_lines = data_list[1].readlines()\n",
        "\n",
        "english_lines = []\n",
        "\n",
        "for line in bytecode_lines:\n",
        "  english_lines.append(line.decode('utf-8').strip('\\n'))\n",
        "  \n",
        "hindi_lines = []\n",
        "bytecode_lines = data_list[0].readlines()\n",
        "\n",
        "for line in bytecode_lines:\n",
        "  hindi_lines.append(line.decode('utf-8').strip('\\n'))\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xmm5MrNftCyW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Some helper functions to read the data, create pairs and the language vocabularies."
      ]
    },
    {
      "metadata": {
        "id": "uankOoTls5bq",
        "colab_type": "code",
        "outputId": "7f2135d2-e0ac-4a7a-be45-6032e4e6f561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "def addWordsToLang(lang, lines):\n",
        "    for line in lines:\n",
        "        lang.addSentence(line)\n",
        "    \n",
        "    return lang\n",
        "\n",
        "def create_pairs(lang1, lang2):\n",
        "    pairs = []\n",
        "\n",
        "    for lang1_sent, lang2_sent in zip(lang1, lang2):\n",
        "        pairs.append([lang1_sent, lang2_sent])\n",
        "        \n",
        "    return pairs\n",
        "\n",
        "def createLanguagesAndPairs(lang1_lines, lang2_lines, lang1, lang2):\n",
        "    \n",
        "    print('Creating pairs...')\n",
        "    pairs = create_pairs(lang1_lines, lang2_lines)\n",
        "    \n",
        "    print('Adding words to languages')\n",
        "    lang1 = addWordsToLang(lang1, lang1_lines)\n",
        "    lang2 = addWordsToLang(lang2, lang2_lines)\n",
        "    \n",
        "    print('Done creating languages')\n",
        "    \n",
        "    return pairs, lang1, lang2\n",
        "  \n",
        "pairs, hindi_lang, english_lang = createLanguagesAndPairs(hindi_lines, english_lines, hindi_lang, english_lang)\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating pairs...\n",
            "Adding words to languages\n",
            "Done creating languages\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r1CyMlN3Sqvl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Encoder RNN\n",
        "Create an Encoder RNN. \n",
        "It takes the input size which is the number of words in the input language vocabulary.\n",
        "The other argument is the hidden state dimension. The dimensions of the embedidng is also the same as the hidden state dimensions.\n",
        "\n",
        "\n",
        "\n",
        "![The Encoder RNN Image](https://pytorch.org/tutorials/_images/encoder-network.png)"
      ]
    },
    {
      "metadata": {
        "id": "4R5273ecSqc0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    \n",
        "  def forward(self, input, hidden_state):\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\n",
        "    output = embedded\n",
        "    output, hidden_state = self.gru(output, hidden_state)\n",
        "    return output, hidden_state\n",
        "  \n",
        "  def initHidden(self):\n",
        "    return torch.randn(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7N2skMGdUOL-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Create Decoder RNN\n",
        "Create the DecoderRNN. It takes the hidden unit dimensions and the number of words in the output language vocabulary.\n",
        "\n",
        "\n",
        "![DecoderRNN architecture](https://pytorch.org/tutorials/_images/decoder-network.png)"
      ]
    },
    {
      "metadata": {
        "id": "R-ya0R_BUn4p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, input, hidden_state):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden_state)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden_state\n",
        "    \n",
        "    def initHidden(self):\n",
        "        return torch.randn(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ly5NOpzMUuud",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Training section.\n",
        "Some functions to create a sequence of inputs for each sentence pair.\n"
      ]
    },
    {
      "metadata": {
        "id": "eOX6A3jvU3I0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1819
        },
        "outputId": "2c49b795-2f1f-4bbb-c14c-6bd0bb58b7e8"
      },
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "    \n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorFromPairs(pair):\n",
        "    input_tensor = tensorFromSentence(hindi_lang, pair[0])\n",
        "    output_tensor = tensorFromSentence(english_lang, pair[1])\n",
        "    return (input_tensor, output_tensor)\n",
        "\n",
        "# This section is for testing the outputs of the Encoder\n",
        "input_tensor, output_tensor = tensorFromPairs(pairs[0])\n",
        "\n",
        "HIDDEN_DIM = 256\n",
        "encoder = EncoderRNN(english_lang.n_words, HIDDEN_DIM).to(device)\n",
        "decoder = DecoderRNN(HIDDEN_DIM, hindi_lang.n_words).to(device)\n",
        "\n",
        "encoder_hidden = encoder.initHidden()\n",
        "\n",
        "encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n",
        "decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n",
        "\n",
        "encoder_optimizer.zero_grad()\n",
        "decoder_optimizer.zero_grad()\n",
        "\n",
        "encoder_output, encoder_hidden = encoder(input_tensor[0], encoder_hidden)\n",
        "\n",
        "print(f'encoder_output- \\n{encoder_output}\\nencoder_hidden- {encoder_hidden}\\n')\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_output- \n",
            "tensor([[[-6.5354e-01,  3.9343e-01,  2.6896e-01, -1.3375e-02,  3.9268e-01,\n",
            "          -7.6958e-01, -2.9768e-01,  4.2736e-01,  3.3459e-01, -5.3247e-01,\n",
            "           2.0292e-02,  2.7373e-02,  1.0472e+00,  2.3910e-01,  8.1970e-01,\n",
            "           1.7460e-01,  1.3259e-01,  3.1073e-01, -4.4761e-01,  4.0740e-01,\n",
            "           1.0853e+00, -6.5767e-01, -8.3248e-01, -1.9622e-01, -1.2883e-01,\n",
            "          -4.9259e-02, -1.5747e-01,  8.7821e-01, -5.7472e-01, -8.7642e-01,\n",
            "           3.1659e-01, -5.1393e-01,  7.3229e-01, -8.1574e-01, -1.8101e-01,\n",
            "          -4.2936e-01, -6.9078e-01,  9.5986e-01,  6.1059e-01, -1.4773e-01,\n",
            "           6.1398e-01, -2.7758e-01, -1.3197e-01,  1.0878e+00,  3.2755e-01,\n",
            "           4.8859e-01,  2.0760e-01,  1.5745e-02,  9.1674e-01,  6.4979e-02,\n",
            "          -3.9689e-01,  3.8731e-01, -5.7504e-01,  1.2688e+00, -6.5922e-01,\n",
            "           9.0253e-01,  1.2001e+00, -6.1024e-02,  1.1487e-01,  1.3972e-01,\n",
            "           6.3041e-01,  4.7182e-01, -1.0206e+00, -9.3904e-02, -1.2729e+00,\n",
            "           2.5193e-01, -5.1038e-01, -4.6704e-01, -1.1954e+00,  1.4040e-01,\n",
            "           3.9788e-01,  4.9570e-01,  1.0727e-01, -1.5852e-01,  6.8420e-01,\n",
            "          -8.5753e-01,  7.1449e-01,  7.5619e-02,  1.3840e-01,  4.8176e-01,\n",
            "           4.8512e-01, -1.0346e+00,  5.5274e-01, -5.9871e-01, -1.2760e-01,\n",
            "          -2.0618e-01,  3.6044e-01,  7.6579e-01, -6.4062e-01,  1.9399e-01,\n",
            "           1.9922e-01,  5.7751e-01,  2.0942e-01,  1.1733e+00,  5.0179e-01,\n",
            "           1.2304e+00, -1.0639e+00,  1.9885e-01,  1.4299e-02,  1.8869e-02,\n",
            "           3.2034e-01,  3.1129e-01,  8.7148e-01, -4.1418e-01,  7.8362e-01,\n",
            "           4.2202e-03, -5.9789e-01,  4.6851e-01, -1.6014e-03, -2.1954e-01,\n",
            "           2.3943e-01,  2.0091e-01,  6.0461e-01, -2.0183e-01,  2.3283e-02,\n",
            "           5.5345e-03, -1.0520e+00,  3.9628e-01,  9.8027e-01, -1.3154e+00,\n",
            "          -7.9194e-01, -2.4418e-01,  2.5809e-01, -6.5186e-02, -1.9741e-01,\n",
            "          -9.1087e-01,  1.3048e-01, -2.3986e-01, -4.8119e-02, -5.2008e-01,\n",
            "          -1.1007e+00, -1.6298e-01,  1.8434e-02,  2.9961e-01, -5.2263e-01,\n",
            "          -3.3738e-01,  1.3775e-02,  6.5870e-01,  5.3397e-01,  8.2065e-01,\n",
            "          -2.8802e-01, -1.1718e-01, -4.2122e-01,  9.0878e-02,  3.6644e-01,\n",
            "           4.4719e-01, -6.4862e-01,  2.7330e-01, -3.1493e-01, -3.1970e-01,\n",
            "          -7.4681e-01, -4.6037e-01,  8.3463e-01,  2.3543e-03,  8.3662e-01,\n",
            "           4.7664e-01, -2.0393e-01,  1.2448e-01,  1.5619e-02, -8.3813e-01,\n",
            "           1.0296e-01,  2.7037e-01, -1.4614e-01,  1.4012e+00,  1.1130e-01,\n",
            "           3.1619e-01,  2.0687e-01, -3.0563e-01,  3.3375e-01, -1.3972e-01,\n",
            "          -3.6016e-01,  6.7326e-03, -3.2139e-01, -8.5838e-02,  7.8919e-02,\n",
            "           4.8803e-01, -5.4873e-01, -2.1620e-01,  5.6183e-01, -6.5839e-01,\n",
            "           7.2948e-01,  5.9614e-01, -4.6932e-01,  1.1227e+00, -5.8974e-01,\n",
            "           5.6128e-01, -2.0174e+00,  9.0895e-01,  8.8110e-01,  3.2393e-01,\n",
            "           2.8005e-01,  1.1396e+00, -9.7150e-02,  7.2808e-01, -1.3882e-01,\n",
            "          -1.9043e-01, -7.4571e-02,  9.0673e-01, -1.2708e-01,  3.1230e-01,\n",
            "          -5.4080e-01,  6.8572e-01,  4.5668e-01,  5.5716e-01, -3.1758e-01,\n",
            "           8.2788e-01,  1.3621e-01,  8.3764e-01,  8.1537e-01, -2.3314e-01,\n",
            "           1.3707e-01,  3.7181e-01, -2.3001e-01,  1.2827e-01,  3.3569e-01,\n",
            "           6.6885e-01, -7.9587e-01, -1.9426e-02,  8.6239e-01, -2.0876e-01,\n",
            "          -1.8760e-02,  4.6134e-01, -1.2517e+00, -2.5391e-01,  5.1849e-01,\n",
            "           9.2042e-02, -2.1612e-01, -4.8635e-01,  1.4307e-01,  4.4089e-02,\n",
            "           1.6439e-01,  3.0614e-01, -4.9824e-01,  7.8400e-01, -6.1853e-01,\n",
            "          -1.0873e-01,  6.7566e-01,  3.3082e-02,  3.9485e-01,  1.8687e-01,\n",
            "           7.8823e-01, -6.3839e-01, -1.8253e-01, -1.4514e-01,  7.5852e-01,\n",
            "           2.3959e-01,  4.0238e-01, -7.7579e-01,  2.9428e-01, -5.6554e-01,\n",
            "           1.9872e-02, -1.1165e+00,  9.1667e-01,  8.5217e-01,  1.8958e-01,\n",
            "          -2.4714e-01]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "encoder_hidden- tensor([[[-6.5354e-01,  3.9343e-01,  2.6896e-01, -1.3375e-02,  3.9268e-01,\n",
            "          -7.6958e-01, -2.9768e-01,  4.2736e-01,  3.3459e-01, -5.3247e-01,\n",
            "           2.0292e-02,  2.7373e-02,  1.0472e+00,  2.3910e-01,  8.1970e-01,\n",
            "           1.7460e-01,  1.3259e-01,  3.1073e-01, -4.4761e-01,  4.0740e-01,\n",
            "           1.0853e+00, -6.5767e-01, -8.3248e-01, -1.9622e-01, -1.2883e-01,\n",
            "          -4.9259e-02, -1.5747e-01,  8.7821e-01, -5.7472e-01, -8.7642e-01,\n",
            "           3.1659e-01, -5.1393e-01,  7.3229e-01, -8.1574e-01, -1.8101e-01,\n",
            "          -4.2936e-01, -6.9078e-01,  9.5986e-01,  6.1059e-01, -1.4773e-01,\n",
            "           6.1398e-01, -2.7758e-01, -1.3197e-01,  1.0878e+00,  3.2755e-01,\n",
            "           4.8859e-01,  2.0760e-01,  1.5745e-02,  9.1674e-01,  6.4979e-02,\n",
            "          -3.9689e-01,  3.8731e-01, -5.7504e-01,  1.2688e+00, -6.5922e-01,\n",
            "           9.0253e-01,  1.2001e+00, -6.1024e-02,  1.1487e-01,  1.3972e-01,\n",
            "           6.3041e-01,  4.7182e-01, -1.0206e+00, -9.3904e-02, -1.2729e+00,\n",
            "           2.5193e-01, -5.1038e-01, -4.6704e-01, -1.1954e+00,  1.4040e-01,\n",
            "           3.9788e-01,  4.9570e-01,  1.0727e-01, -1.5852e-01,  6.8420e-01,\n",
            "          -8.5753e-01,  7.1449e-01,  7.5619e-02,  1.3840e-01,  4.8176e-01,\n",
            "           4.8512e-01, -1.0346e+00,  5.5274e-01, -5.9871e-01, -1.2760e-01,\n",
            "          -2.0618e-01,  3.6044e-01,  7.6579e-01, -6.4062e-01,  1.9399e-01,\n",
            "           1.9922e-01,  5.7751e-01,  2.0942e-01,  1.1733e+00,  5.0179e-01,\n",
            "           1.2304e+00, -1.0639e+00,  1.9885e-01,  1.4299e-02,  1.8869e-02,\n",
            "           3.2034e-01,  3.1129e-01,  8.7148e-01, -4.1418e-01,  7.8362e-01,\n",
            "           4.2202e-03, -5.9789e-01,  4.6851e-01, -1.6014e-03, -2.1954e-01,\n",
            "           2.3943e-01,  2.0091e-01,  6.0461e-01, -2.0183e-01,  2.3283e-02,\n",
            "           5.5345e-03, -1.0520e+00,  3.9628e-01,  9.8027e-01, -1.3154e+00,\n",
            "          -7.9194e-01, -2.4418e-01,  2.5809e-01, -6.5186e-02, -1.9741e-01,\n",
            "          -9.1087e-01,  1.3048e-01, -2.3986e-01, -4.8119e-02, -5.2008e-01,\n",
            "          -1.1007e+00, -1.6298e-01,  1.8434e-02,  2.9961e-01, -5.2263e-01,\n",
            "          -3.3738e-01,  1.3775e-02,  6.5870e-01,  5.3397e-01,  8.2065e-01,\n",
            "          -2.8802e-01, -1.1718e-01, -4.2122e-01,  9.0878e-02,  3.6644e-01,\n",
            "           4.4719e-01, -6.4862e-01,  2.7330e-01, -3.1493e-01, -3.1970e-01,\n",
            "          -7.4681e-01, -4.6037e-01,  8.3463e-01,  2.3543e-03,  8.3662e-01,\n",
            "           4.7664e-01, -2.0393e-01,  1.2448e-01,  1.5619e-02, -8.3813e-01,\n",
            "           1.0296e-01,  2.7037e-01, -1.4614e-01,  1.4012e+00,  1.1130e-01,\n",
            "           3.1619e-01,  2.0687e-01, -3.0563e-01,  3.3375e-01, -1.3972e-01,\n",
            "          -3.6016e-01,  6.7326e-03, -3.2139e-01, -8.5838e-02,  7.8919e-02,\n",
            "           4.8803e-01, -5.4873e-01, -2.1620e-01,  5.6183e-01, -6.5839e-01,\n",
            "           7.2948e-01,  5.9614e-01, -4.6932e-01,  1.1227e+00, -5.8974e-01,\n",
            "           5.6128e-01, -2.0174e+00,  9.0895e-01,  8.8110e-01,  3.2393e-01,\n",
            "           2.8005e-01,  1.1396e+00, -9.7150e-02,  7.2808e-01, -1.3882e-01,\n",
            "          -1.9043e-01, -7.4571e-02,  9.0673e-01, -1.2708e-01,  3.1230e-01,\n",
            "          -5.4080e-01,  6.8572e-01,  4.5668e-01,  5.5716e-01, -3.1758e-01,\n",
            "           8.2788e-01,  1.3621e-01,  8.3764e-01,  8.1537e-01, -2.3314e-01,\n",
            "           1.3707e-01,  3.7181e-01, -2.3001e-01,  1.2827e-01,  3.3569e-01,\n",
            "           6.6885e-01, -7.9587e-01, -1.9426e-02,  8.6239e-01, -2.0876e-01,\n",
            "          -1.8760e-02,  4.6134e-01, -1.2517e+00, -2.5391e-01,  5.1849e-01,\n",
            "           9.2042e-02, -2.1612e-01, -4.8635e-01,  1.4307e-01,  4.4089e-02,\n",
            "           1.6439e-01,  3.0614e-01, -4.9824e-01,  7.8400e-01, -6.1853e-01,\n",
            "          -1.0873e-01,  6.7566e-01,  3.3082e-02,  3.9485e-01,  1.8687e-01,\n",
            "           7.8823e-01, -6.3839e-01, -1.8253e-01, -1.4514e-01,  7.5852e-01,\n",
            "           2.3959e-01,  4.0238e-01, -7.7579e-01,  2.9428e-01, -5.6554e-01,\n",
            "           1.9872e-02, -1.1165e+00,  9.1667e-01,  8.5217e-01,  1.8958e-01,\n",
            "          -2.4714e-01]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hZ1QyhNDVhNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "c31d1189-4ef1-43c2-fbf7-f870d83360f0"
      },
      "cell_type": "code",
      "source": [
        "encoder_output[0, 0]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-6.5354e-01,  3.9343e-01,  2.6896e-01, -1.3375e-02,  3.9268e-01,\n",
              "        -7.6958e-01, -2.9768e-01,  4.2736e-01,  3.3459e-01, -5.3247e-01,\n",
              "         2.0292e-02,  2.7373e-02,  1.0472e+00,  2.3910e-01,  8.1970e-01,\n",
              "         1.7460e-01,  1.3259e-01,  3.1073e-01, -4.4761e-01,  4.0740e-01,\n",
              "         1.0853e+00, -6.5767e-01, -8.3248e-01, -1.9622e-01, -1.2883e-01,\n",
              "        -4.9259e-02, -1.5747e-01,  8.7821e-01, -5.7472e-01, -8.7642e-01,\n",
              "         3.1659e-01, -5.1393e-01,  7.3229e-01, -8.1574e-01, -1.8101e-01,\n",
              "        -4.2936e-01, -6.9078e-01,  9.5986e-01,  6.1059e-01, -1.4773e-01,\n",
              "         6.1398e-01, -2.7758e-01, -1.3197e-01,  1.0878e+00,  3.2755e-01,\n",
              "         4.8859e-01,  2.0760e-01,  1.5745e-02,  9.1674e-01,  6.4979e-02,\n",
              "        -3.9689e-01,  3.8731e-01, -5.7504e-01,  1.2688e+00, -6.5922e-01,\n",
              "         9.0253e-01,  1.2001e+00, -6.1024e-02,  1.1487e-01,  1.3972e-01,\n",
              "         6.3041e-01,  4.7182e-01, -1.0206e+00, -9.3904e-02, -1.2729e+00,\n",
              "         2.5193e-01, -5.1038e-01, -4.6704e-01, -1.1954e+00,  1.4040e-01,\n",
              "         3.9788e-01,  4.9570e-01,  1.0727e-01, -1.5852e-01,  6.8420e-01,\n",
              "        -8.5753e-01,  7.1449e-01,  7.5619e-02,  1.3840e-01,  4.8176e-01,\n",
              "         4.8512e-01, -1.0346e+00,  5.5274e-01, -5.9871e-01, -1.2760e-01,\n",
              "        -2.0618e-01,  3.6044e-01,  7.6579e-01, -6.4062e-01,  1.9399e-01,\n",
              "         1.9922e-01,  5.7751e-01,  2.0942e-01,  1.1733e+00,  5.0179e-01,\n",
              "         1.2304e+00, -1.0639e+00,  1.9885e-01,  1.4299e-02,  1.8869e-02,\n",
              "         3.2034e-01,  3.1129e-01,  8.7148e-01, -4.1418e-01,  7.8362e-01,\n",
              "         4.2202e-03, -5.9789e-01,  4.6851e-01, -1.6014e-03, -2.1954e-01,\n",
              "         2.3943e-01,  2.0091e-01,  6.0461e-01, -2.0183e-01,  2.3283e-02,\n",
              "         5.5345e-03, -1.0520e+00,  3.9628e-01,  9.8027e-01, -1.3154e+00,\n",
              "        -7.9194e-01, -2.4418e-01,  2.5809e-01, -6.5186e-02, -1.9741e-01,\n",
              "        -9.1087e-01,  1.3048e-01, -2.3986e-01, -4.8119e-02, -5.2008e-01,\n",
              "        -1.1007e+00, -1.6298e-01,  1.8434e-02,  2.9961e-01, -5.2263e-01,\n",
              "        -3.3738e-01,  1.3775e-02,  6.5870e-01,  5.3397e-01,  8.2065e-01,\n",
              "        -2.8802e-01, -1.1718e-01, -4.2122e-01,  9.0878e-02,  3.6644e-01,\n",
              "         4.4719e-01, -6.4862e-01,  2.7330e-01, -3.1493e-01, -3.1970e-01,\n",
              "        -7.4681e-01, -4.6037e-01,  8.3463e-01,  2.3543e-03,  8.3662e-01,\n",
              "         4.7664e-01, -2.0393e-01,  1.2448e-01,  1.5619e-02, -8.3813e-01,\n",
              "         1.0296e-01,  2.7037e-01, -1.4614e-01,  1.4012e+00,  1.1130e-01,\n",
              "         3.1619e-01,  2.0687e-01, -3.0563e-01,  3.3375e-01, -1.3972e-01,\n",
              "        -3.6016e-01,  6.7326e-03, -3.2139e-01, -8.5838e-02,  7.8919e-02,\n",
              "         4.8803e-01, -5.4873e-01, -2.1620e-01,  5.6183e-01, -6.5839e-01,\n",
              "         7.2948e-01,  5.9614e-01, -4.6932e-01,  1.1227e+00, -5.8974e-01,\n",
              "         5.6128e-01, -2.0174e+00,  9.0895e-01,  8.8110e-01,  3.2393e-01,\n",
              "         2.8005e-01,  1.1396e+00, -9.7150e-02,  7.2808e-01, -1.3882e-01,\n",
              "        -1.9043e-01, -7.4571e-02,  9.0673e-01, -1.2708e-01,  3.1230e-01,\n",
              "        -5.4080e-01,  6.8572e-01,  4.5668e-01,  5.5716e-01, -3.1758e-01,\n",
              "         8.2788e-01,  1.3621e-01,  8.3764e-01,  8.1537e-01, -2.3314e-01,\n",
              "         1.3707e-01,  3.7181e-01, -2.3001e-01,  1.2827e-01,  3.3569e-01,\n",
              "         6.6885e-01, -7.9587e-01, -1.9426e-02,  8.6239e-01, -2.0876e-01,\n",
              "        -1.8760e-02,  4.6134e-01, -1.2517e+00, -2.5391e-01,  5.1849e-01,\n",
              "         9.2042e-02, -2.1612e-01, -4.8635e-01,  1.4307e-01,  4.4089e-02,\n",
              "         1.6439e-01,  3.0614e-01, -4.9824e-01,  7.8400e-01, -6.1853e-01,\n",
              "        -1.0873e-01,  6.7566e-01,  3.3082e-02,  3.9485e-01,  1.8687e-01,\n",
              "         7.8823e-01, -6.3839e-01, -1.8253e-01, -1.4514e-01,  7.5852e-01,\n",
              "         2.3959e-01,  4.0238e-01, -7.7579e-01,  2.9428e-01, -5.6554e-01,\n",
              "         1.9872e-02, -1.1165e+00,  9.1667e-01,  8.5217e-01,  1.8958e-01,\n",
              "        -2.4714e-01], device='cuda:0', grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    }
  ]
}